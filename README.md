# data-pipeline-with-spark-kafka
This real-time COVID-19 data pipeline uses Apache Kafka for ingestion, Spark Streaming for aggregation (new cases by location), and Apache Airflow for orchestration. All components are containerised and deployed using Docker Compose, providing a portable and reproducible development environment.
